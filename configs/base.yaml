base_model: "mistralai/Mistral-7B-Instruct-v0.3"
train_file: "data/train.jsonl"
eval_file: "data/val.jsonl"
output_dir: "runs/mistral7b_qlora_domainqa"
per_device_train_batch_size: 1
gradient_accumulation_steps: 8
learning_rate: 1e-4
num_train_epochs: 3
logging_steps: 10
eval_steps: 200
save_steps: 500
bnb_4bit: true
fp16: true
bf16: false
max_seq_length: 2048
packing: true
report_to: "none"
seed: 42
